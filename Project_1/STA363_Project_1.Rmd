---
title: "STA363 Project 1"
author: "Zishan Shao"
date: "2022-09-05"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
set.seed(114514)
```


```{r}
# load the data from the dataset
dengue <- read.csv("../Project_1/dengueData.csv", header = TRUE)
```

\pagebreak


\begin{abstract}

  Dengue is a viral disease spreading worldwide. It could cause acute symptoms and irreversible damage to personal health without medical care. Even worse, dengue is difficult to diagnose without accession to advanced medicare. Therefore, it is necessary to develop an efficient model that could relatively accurately diagnose the disease with suspicious symptoms. The main goal of this report is to create a model that accurately predicts (by classifying) dengue patients by evaluating clinical data collected from Vietnam hospitals. Considering the nature of the response variable, we decided to choose between the K-Nearest Neighbor (KNN) based model and the multivariable logistic regression model to fulfill the task. To determine the prediction capacity of the two models, we used accuracy, sensitivity, and specificity as evaluation metrics to make the choice. Finally, we compare three metrics of KNN based model and the multivariable logistic regression model and decided to choose the multivariable logistic regression model (Model 2) as our final model from the statistical and practical considerations. The model has 74.1\% of accuracy, 90.9\% of sensitivity, and 34.7\% of specificity.
  
  


\end{abstract}




\pagebreak


\tableofcontents


\pagebreak


# Section 1: Introduction and Data

 In this report, we are working with patient data from the local hospitals in Vietnam. The data was composed of 5726 children who have symptoms of dengue fever when they were brought to clinics. Dengue was \textit{a viral infection transmitted to humans through the bite of infected mosquitoes with dengue virus (DENV)}. While most of them only develop a mild illness, some develop into a potentially lethal complication, called severe dengue  \footnote{“Dengue and Severe Dengue.” World Health Organization, World Health Organization, https://www.who.int/news-room/fact-sheets/detail/dengue-and-severe-dengue. }. The study of dengue has long been conducted worldwide, but detection method without the accession of advanced medical care is yet to be invented. This caused difficulty in the diagnosis of dengue in underdeveloped regions. Therefore, the main goal of this analysis is to construct a relatively applicable statistical model that efficiently, yet accurately, predicts dengue with common symptoms of the disease. The model will be built with features that have the highest potential influence on the response variable (label) and trained with the data from real-life data. The model is expected to be applicable in most places in the world even without the accession of advanced medication, so the simplicity of the model will also be considered. Finally, we expected to select the best model from multiple trained models with different tuning parameters, thresholds, and sampling techniques. We will evaluate our model based on precision metrics of statistical models (e.g. accuracy, sensitivity, specificity).


### Label Analysis & Data Cleaning

```{r, fig.width=4.5,fig.height=2.5, fig.align='center'}
# data cleaning & label analysis

# total number of features
numFeatures <- ncol(dengue)

# construct the barplot of the label
suppressMessages(library(ggplot2))   # import the ggplot2 for plotting
ggplot(dengue, aes(x=Y)) + geom_bar(fill='steelblue') +
  labs(x='Dengue Fever (Y = 1: Positive/True ; Y = 0: Negative/False)', main = " ")
```

\begin{center}
Figure 1.1: Barplot of Label Y
\end{center}

  In this data, there are a total of 15 variables comprised of 14 features (categorical or numerical) and 1 label. Our goal is to predict the label Y according to features with different weights. Meanwhile, the Y is a binary variable: Y = 1 means the patient has dengue fever and Y = 0 means the patient does not have dengue fever. In other words, this report is dealing with a prediction task with a classification problem. From Figure 1.1, we could see that the distribution of the outcomes (0 & 1) is about 1: 2.5 in ratio, which is valid for model building because there is a fair chance to meet each scenario. 

```{r}
# Data Cleaning

# total number of observations
n <- nrow(dengue)
dengueClean <- na.omit(dengue)
nclean <- nrow(dengueClean)           

# number of observations before/after
nobs <- matrix(c(n,nclean), nrow = 2, ncol = 1)
rownames(nobs) <- c("Before Cleaning", "After Cleaning")

# table of observations before/after the cleaning
knitr::kable(nobs, col = "Num Observations",caption = "Data Cleaning")
```

  Along with the label analysis, it is also necessary to clean the data by removing or refilling the rows with missing information. However, the cleaning results indicate that the total observation number remains unchanged after the cleaning (both equal to 5726), indicating that there is no missing data existed in the explanatory variables. This also indicates there is no missed information in any features (indicated by columns), so the dimension of the entire data set remains same. Therefore, we proceed to construct the model.


# Section 2: K-Nearest Neighbor (KNN)

  Because the label Y is a binary variable, there are two kinds of ubiquitous methods to apply: multivariable logistic regression model (MLR) and K-Nearest Neighbor (KNN). The KNN is a clustering technique/algorithm that is effective in classifying labels based on the neighboring outcomes. The KNN assumes that similarity exists among outcomes of nearby observations, and is effective if there is a clustering of outcomes in the data. Therefore, KNN is expected to be suitable because the diagnosis of dengue is difficult without the accession of the standard test.

## 2.1: Brief Example of K-Nearest Neighbor (KNN) 

  KNN algorithm is surprisingly simple for interpretation. In the following example, a mock sample was provided with age = 8 and height = 100 cm, and a KNN-based model was constructed with the feature Age and Height. We set the tuning parameter k, the number of neighbors for consideration, equal to 5 and make predictions with the model and a scatterplot.

```{r}
# Example of KNN using Age and Height

# create the exampleSet with the feature: Age and Height with label Y
exampleSet <- dengueClean[,c(2,10,15)]
colnames(exampleSet) = c("Age", "Height", "DengueOrNot")  # reset the names, especially for the label Y
exampleSet$DengueOrNot <- as.character(exampleSet$DengueOrNot)  # set the labels as character for later naming in the plot

# create the train-test set with train-test 80:20 split method (I may not use this one in
# later modeling, but it serve as an efficient example)
set.seed(114514)  # set the seed everytime you need sampling
exampleTestRow <- sample(1:nrow(exampleSet), nrow(exampleSet)*0.2)

exampleTest <- exampleSet[exampleTestRow,]  # create the testing data
exampleTrain <- exampleSet[-exampleTestRow,]  # create the training data

# create the KNN model
suppressMessages(library(class))
# when train the model, read only the features and add the labels for the train set for parameter cl
# the model is to predict the Y value of the test
results <- knn(train = exampleTrain[,c(1,2)], test = exampleTest[,c(1,2)], cl = exampleTrain$DengueOrNot, k = 5)
```


### Prediction with Scatterplot & Model

```{r, warning=FALSE, fig.width=5, fig.height=4, fig.align='center'}
# Prediction Making with Scatterplot

suppressMessages(library(ggplot2))   # import the ggplot2 for plotting the empirical logit plot while suppressing useless warning information
ggplot(exampleSet, aes(x=Age, y = Height, color = DengueOrNot)) + geom_point() + labs(title =" ", x = "Age (in years)", y = "Height (in cm)") + xlim(8,8) + ylim(80, 120) + geom_point(aes(x=8, y=100), colour="black")
```

\begin{center}
Figure 2.1.1: Scatterplot of Age \& Height (Age = 8)
\end{center}

  Figure 2.1.1 provides all observations with age = 8. The orange dots indicate that the patient is negative and the cyan dots indicates the patient is positive. The black point, which is the mock observation, lies at 100 cm in height. The closest 5 observations to the mock observation have the outcome of [0,1,1,1,1], in which the positive result was the mode of the neighbors. Therefore, it is likely that, by assumption, the mock observation also has a positive outcome.

  The model prediction also supports our prediction with the scatterplot. The predicted label of the mock observation indicates that the result should be Y = 1, which means the kid gets dengue fever. 

  However, the prediction result does not necessarily reflect the accuracy of the model. To determine if this model is effective, we need to compare the performance metrics such as geometric means of KNN models adapting different sampling methods or tuning parameters. This part will not be specified in the example but will be included and explained later. 


```{r}
### prediction making via KNN model

# Given that a child has age = 8 and 100 cm tall, we could set them as test set and make prediction
singleTest <- c(8,100)
# print(singleTest)
results <- knn(train = exampleTrain[,c(1,2)], test = singleTest, cl = exampleTrain$DengueOrNot, k = 5)  # predict the test set with trained model
```



## 2.2: KNN models (with all features) & train-test split method

   In section 2.2, we will construct our first model with all 14 features via the train-test split method. The train-test split method, by its name, splits the data into training and testing datasets. It is necessary when the testing dataset was not provided and was effective in minimizing the overfitting problem. In this case, I will compare the traditional train-test split by 20% to 80% split and k-fold cross-validation to construct the train-test dataset. 

  The tuning parameter is also considered. The k is the tuning parameter of every KNN-based model, which defines the number of neighbors to be considered. This parameter enables the KNN algorithm to adapt to different scenarios. For instance, if the sample size was very small, the neighbor number should be comparably smaller than the neighbor numbers in relatively larger datasets. In this case, I will construct models with k = 3, 5, 7, 9 and compare their geometric means (computed by the square root of sensitivity x specificity). The model with the highest geometric mean will be selected.


### Train-Test Spliting

```{r}
set.seed(114514)
# train-test split
# randomly sample the numbers from an ordered vector from 1 to 5726 to represent the 
# row indices for the testing set, later we could directly slice the data with the 
# indices collected here
testRow <- sample(1:nrow(dengueClean), nrow(dengueClean)*0.2)   

# creating the test set with observations with indices in testRow vector (20% of total data)
newTest <- dengueClean[testRow,]  
# sprintf("Num observations in test set: %d", nrow(newTest))
# creating the training set with observations with indices not in testRow vector (80% of total data)
newTrain <- dengueClean[-testRow,]
# sprintf("Num observations in training set: %d", nrow(newTrain))

# find the number of true dengue fever people (Y = 1) and true non-dengue people (Y = 0)
# find the number of positive dengue cases in newTest
trueDengueS <- which(newTest$Y == 1)
ntrueDengueS <- length(trueDengueS)
# sprintf("True Dengue Number in test set: %d", ntrueDengueS)

# find the number of negative dengue cases in newTest
trueNotDengueS <- which(newTest$Y == 0)
ntrueNotDengueS <- length(trueNotDengueS)
# sprintf("True Not Dengue Number in test set: %d", ntrueNotDengueS)

# create the table for the observation numbers in each sets
nobsSplit <- c(nrow(newTest), nrow(newTrain), ntrueDengueS, ntrueNotDengueS)
nobsSplit <- matrix(nobsSplit, nrow = 4, ncol = 1)
rownames(nobsSplit) <- c("Num observations in test set", "Num observations in training set", "True Dengue Number in test set", "True Not Dengue Number in test set")
knitr::kable(nobsSplit, col = "Count", caption = "Observations in Train/Test Sets & True/False Counts")
```

  The training set has 4581 observations and the test set has 1145 observations, which in total has 5726 observations. The test set includes 803 patients who were diagnosed with dengue and 342 patients who do not diagnose with dengue. The later two numbers are essential for the computation of geometric means. 


### Model Creation (via loop)

  To create and compare models with different tuning parameters, a loop is adapted to iteratively train and test the model. The predicted result was recorded in a 4x2 data frame with a value of k and a corresponding geometric mean (GMean) in table 3. 

```{r}
# create the KNN model
library(class)

# initialize the repository of the result
# because there are totally 4 different values of the k, so the data should have 4 sets of K and geometric means
splitResult <- data.frame("K" = rep(NA, 4), "GMean" = rep(NA,4))

# create the index of the splitResult
j = 1

# the train and test data should include all features, which is the columns from 1 to 14
for (i in c(3, 5, 7, 9)) {
  # loop over tuning variable k with different values, record the information in splitResult
  results <- knn(train = newTrain[,c(1:14)], test = newTest[,c(1:14)], cl = newTrain$Y, k = i)
  splitResult$K[j] = i
  
  # sensitivity
  sensitivity = sum(results[trueDengueS] == 1)/ntrueDengueS
    
  # specificity
  specificity = sum(results[trueNotDengueS] == 0)/ntrueNotDengueS  
  
  # calculate the geometric mean with two metrics above
  splitResult$GMean[j] = round(sqrt(sensitivity*specificity), 3)
  
  j = j + 1 # so that it sets the index for splitResult
}

# create the table for the results
knitr::kable(splitResult, col.names = c("K", "Geometric Mean"), caption= "Models with different k values with train-test split method")
```

  Table 3 indicates that k = 5 has the highest geometric mean, indicating that, at k = 5, the model classifies the observations at the highest precision because this means we have the highest proportion of correctly classified positive and negative cases. Therefore, the \textbf{k = 5 should be the best choice} from the KNN model built with the train-test split method. 


### Estimation Variation Test

  It is worth mentioning that the train-test split method has two drawbacks. Firstly, it could cause a reduction in training data size by splitting 20% of it into testing data. Such a large proportion of data loss could potentially cause inaccuracy in prediction. Secondly, the randomly chosen rows could cause high estimation variation because the training results are highly dependent on the chosen observations, especially for data sets with a limited number of observations. Therefore, it is necessary to test if an alternative sample could lead to a different conclusion.

```{r}
# resampling the data with a different seed
set.seed(1919810)

testRow <- sample(1:nrow(dengueClean), nrow(dengueClean)*0.2)   

# creating the test set with observations with indices in testRow vector (20% of total data)
newTest <- dengueClean[testRow,]  
# sprintf("Num observations in test set: %d", nrow(newTest))
# creating the training set with observations with indices not in testRow vector (80% of total data)
newTrain <- dengueClean[-testRow,]
# sprintf("Num observations in training set: %d", nrow(newTrain))

# find the number of true dengue fever people (Y = 1) and true non-dengue people (Y = 0)
# find the number of positive dengue cases in newTest
trueDengueS <- which(newTest$Y == 1)
ntrueDengueS <- length(trueDengueS)
# sprintf("True Dengue Number in test set: %d", ntrueDengueS)

# find the number of negative dengue cases in newTest
trueNotDengueS <- which(newTest$Y == 0)
ntrueNotDengueS <- length(trueNotDengueS)
# sprintf("True Not Dengue Number in test set: %d", ntrueNotDengueS)



# create the KNN model
library(class)

# initialize the repository of the result
# because there are totally 4 different values of the k, so the data should have 4 sets of K and geometric means
splitResult <- data.frame("K" = rep(NA, 4), "GMean" = rep(NA,4))

# create the index of the splitResult
j = 1

# the train and test data should include all features, which is the columns from 1 to 14
for (i in c(3, 5, 7, 9)) {
  # loop over tuning variable k with different values, record the information in splitResult
  results <- knn(train = newTrain[,c(1:14)], test = newTest[,c(1:14)], cl = newTrain$Y, k = i)
  splitResult$K[j] = i
  
  # sensitivity
  sensitivity = sum(results[trueDengueS] == 1)/ntrueDengueS
    
  # specificity
  specificity = sum(results[trueNotDengueS] == 0)/ntrueNotDengueS  
  
  # calculate the geometric mean with two metrics above
  splitResult$GMean[j] = round(sqrt(sensitivity*specificity), 3)
  
  j = j + 1 # so that it sets the index for splitResult
}

# create the table for the results
knitr::kable(splitResult, col.names = c("K", "Geometric Mean"), caption= "Models with Resampled Data")

```

  Under seed = 1919810 (previously 114514), the k = 9 obtains a geometric mean equals 0.556, while the k = 5 is 0.555 with 0.001 lower than k = 9. Nonetheless, the closeness of the two geometric means failed to indicate a statistically significant difference in prediction capacity. Meanwhile, the value of the geometric mean of k = 5 only varies by 0.001 when seed = 114514. Therefore, it is proven that the model with k = 5 is not significantly sensitive to the observations chosen.


### Confusion Matrix of KNN (train-test split method) & Metrics Computation

```{r}
# make predictions with k = 5
resultk5 <- knn(train = newTrain[,c(1:14)], test = newTest[,c(1:14)], cl = newTrain$Y, k = 5)

# confusion matrix
knitr::kable(table(resultk5, newTest$Y), caption= "Confusion Matrix of KNN", col = c("True Not Dengue", "True Dengue"))
```

### Metric Computation

$$
Sensitivity = \frac{True Dengue \ \& \ Predicted True Dengue}{Total \ True Dengue} = \frac{696}{696 + 109} \approx 0.865
$$

$$
Specificity = \frac{True Not Dengue\ \& \ Predicted\  True Not Dengue}{Total \ True Not Dengue} = \frac{120}{120 + 220} \approx 0.353
$$

$$
Accuracy = \frac{Total \ Correct \ Predictions}{Total \ Observations} = \frac{696 + 120}{120 + 220 + 696 + 109} \approx 0.713
$$

## 2.3: KNN Models (with All Features) & 10-Fold Cross Validation

  In section 2.3, we applied the 10-fold cross-validation method as the sampling method to obtain the training and testing data. The k-fold cross-validation, like the train-test split, was applied when testing data was not provided. K-fold cross-validation splits the data into k folds and uses each fold's data iteratively as the testing data (the rest data as training data). The results of the prediction will be computed each time with the size of a fold, and finally, the size equals 5726. 

  The two most common fold numbers are 5 and 10. Considering the size of the data, the 10-fold cross-validation should be a more appropriate choice. The dataset was not exactly divisible by 10, so we will create a folder with larger storage space and balance the number of observations in each fold with a difference no larger than 2. This could be achieved by taking the ceiling of the data assigned to folds so that all observations will be sampled to folds.

```{r}
# K-fold Cross Validation: fold creation
# I will apply 10 fold cross validation because there are 5726 total data, which is very large

# record the validation result for different k values
validResult <- data.frame("K" = rep(NA, 4), "GMean" = rep(NA, 4))

# define the number of observations
n <- nrow(dengueClean)

# create the folds
pool <- rep(1:10, ceiling(n/10))

# for convenience purpose, reset the seed here
set.seed(114514)
# randomly assign elements in pool to folds so that fold could contain index of observations to be sampled from dengueClean
folds <- sample(pool,n) 

# create the storage space
storageDenK <- data.frame("YHat" = rep(NA,nrow(dengueClean)))   
# this one was necessary because it will return all prediction data with dim = [5726, 1]
# however, we don't really need all information here, so I will not print and interpret the results
# of storageDenK here.

library(class)  # import the class package for knn

j = 1 # index purpose

for (i in c(3, 5, 7, 9)) {
  validResult$K[j] = i;
  for (f in c(1:10)) {
    # find the data in fold f
    infold <- which(folds ==f)
    
    # define the train and test data sets
    newTrain <- dengueClean[-infold,]
    newTest <- dengueClean[infold,]
    
    # find the number of positive & negative dengue cases in newTest
    ntrue <- length(which(newTest$Y == 1))
    ntrueNot <- length(which(newTest$Y == 0))
    
    # make predictions 
    k_preds <- knn(newTrain[,c(1:14)], newTest[,c(1:14)], cl = newTrain$Y, k = i)
    
    # sensitivity
    sensitivity = sum(k_preds[which(newTest$Y == 1)] == 1)/ntrue
      
    # specificity
    specificity = sum(k_preds[which(newTest$Y == 0)] == 0)/ntrueNot
    
    # calculate the geometric mean with two metrics above
    validResult$GMean[j] = round(sqrt(sensitivity*specificity), 3)
  
    # store predictions
    storageDenK$YHat[infold] <- k_preds
  }
  j = j + 1
}

knitr::kable(validResult, col.names = c("K", "Geometric Mean"), caption= "Models with different k values with 10-Fold Cross Validation")
```

  The testing result in table 6 indicates that the k = 9 with 10-fold cross-validation has the highest geometric mean (0.538), which means that the KNN-based model with k = 9 achieves the highest precision under the 10-fold cross-validation method.
  
### Confusion Matrix of KNN (10-fold cross validation method)

  According to the previous result, we construct our model with k = 9 and fold number = 10. We then construct the confusion matrix of the model and compute the metrics to evaluate the prediction capacity of the model.

```{r}
# confusion matrix of k = 9
knitr::kable(table(storageDenK$YHat, dengueClean$Y), caption= "Confusion matrix (fold=10) of DengueClean", col = c("True Not Dengue", "True Dengue"))
```

### Metrics Computation


$$
Sensitivity = \frac{True Dengue \ \& \ Predicted True Dengue}{Total \ True Dengue} = \frac{3520}{3520 + 508} \approx 0.874
$$


$$
Specificity = \frac{True Not Dengue\ \& \ Predicted\  True Not Dengue}{Total \ True Not Dengue} = \frac{525}{525 + 1173} \approx 0.309
$$

$$
Accuracy = \frac{Total \ Correct \ Predictions}{Total \ Observations} = \frac{525 + 3520}{525 + 3520 + 508 + 1173} \approx 0.706
$$


\vspace{0.5cm}

\begin{center}
\textbf{General Table of Metrics}
\end{center}


|                                                                    |
|------------|----------------|-------------|-------------|----------|
|            | Geometric Mean | Sensitivity | Specificity | Accuracy |
|------------|----------------|-------------|-------------|----------|
| train-test |     0.554      | 86.5%       | 35.3%       | 71.3%    |
| 10-fold    |     0.538      | 87.4%       | 30.9%       | 70.6%    |



  The general table of metrics indicates that the train-test split model has higher geometric mean, specificity, and accuracy, while the 10-fold method has higher sensitivity. Therefore, the KNN-based model with the train-test split method and k = 5 should be our final choice as it has better performance on most metrics.

  The reason behind this result makes sense because the data set is not limited in size. With 5726 observations, it turns out that losing 20% of the data does not harm the prediction capacity of the model or cause a very large estimation variation. What's more, the estimation variation test also indicates that the prediction capacity of the model with k = 5 and the train-test split method is not overly sensitive to the observation selections. Considering that the 10-fold cross-validation method is computationally expensive, the choice of model with k = 5 and the train-test split method makes sense.



# Section 3: Multivariable Logistic Regression

  Noticing that the label Y (Dengue Fever) of the dataset is binary, we could also apply the multivariable logistic regression model in this case. The multivariable logistic regression model is a statistical model that conducts binary classification. It assumes that the binary outcome of a sample follows a Bernoulli distribution and has a population model as follows:


$$
Y_i \sim Bernoulli(\pi_i) 
$$
\textit{where in this case}

$$
\pi_i = P(Y_i = 1|X_i) 
$$

$$
log(\frac{\pi_i}{1-\pi_i}) = \beta_0 + \beta_iX_i, \ \ i \in \{1, 2, ..., n\}
$$
\textit{n is the number of features chosen to be used in the model} 

\break

  In a logistic regression model, we first conduct exploratory data analysis to select features that have visually statistically significant influences on the outcome. Then we construct the model with the features and get rid of variables with p-values larger than 0.05, which means we failed to prove there is a statistically significant relationship between the feature and the label.


## 3.1 Exploratory Data Analysis (EDA)

  The exploratory data analysis provides researchers a chance to explore the relationship between individual features with the label. The logistic regression model requires the feature to be linearly related to the label, which can be explored by the empirical logit plot. If there is a visually non-linear relationship between the feature and the label, we then need to conduct the linear transformation (usually convert the feature to the log of the feature) to fix the non-linearity. However, if the non-linearity exists after the transformation, we could decide to choose another transformation function or choose not to use the feature.
  
### EDA (Part 1): Variable Type Analysis & Standardization

  It is worth mentioning that the linear relationship is only required for numerical features, while the categorical features need mosaic plot to determine their relationship with the model. Therefore, we need to determine the type of the features and convert the defined-numerical features to categorical if they perform more similar to a categorical feature and vice verso.

```{r}
# print the type of features: categorical or numerical
# aa to store the feature name and range
aa <- data.frame("Feature" = rep(NA, ncol(dengueClean)-1), "RangeBegin" = rep(NA, ncol(dengueClean)-1), "RangeEnd" = rep(NA, ncol(dengueClean)-1))

for (i in c(1:14)) {
  aa$Feature[i] = colnames(dengueClean)[i]
  rr = range(dengueClean[colnames(dengueClean)[i]])
  aa$RangeBegin[i] = rr[1]
  aa$RangeEnd[i] = rr[2]
}

knitr::kable(aa, col.names = c("feature", "range begin", "range end"), caption= "Feature Range")

```

  From the feature range table, we noticed that, in the description of features, DayDisease is defined as a numerical rather than a categorical variable. Therefore, we need to convert it to a categorical variable.

```{r}
# convert DayDisease to categorical feature
dengueClean$DayDisease <- as.factor(dengueClean$DayDisease)
```


### EDA (Part 2): Empirical Logit Plots for Categorical Features

  From the feature range of the data, we could see that sex, DayDisease, vomiting, Abdo, Muco, Skin, Flush, Hepatomegaly, and Rash all have only 2 or 3 categories, indicating that these are categorical variables. Therefore, the 5 remaining features are numerical: Age, Temp, BMI, Height, and Weight. We need to construct empirical logit plots for all of these features and explore if there is non-linearity existed.

```{r}
# function for the empirical logit plot
emplogitPlot <- function(x, y, binsize = NULL, ci = FALSE, probit = FALSE,
prob = FALSE, main = NULL, xlab = "", ylab = "", lowess.in = FALSE){
  # x         vector with values of the independent variable
  # y         vector of binary responses
  # binsize   integer value specifying bin size (optional)
  # ci        logical value indicating whether to plot approximate
  #           confidence intervals (not supported as of 02/08/2015)
  # probit    logical value indicating whether to plot probits instead
  #           of logits
  # prob      logical value indicating whether to plot probabilities
  #           without transforming
  #
  # the rest are the familiar plotting options
  
  if(class(y) =="character"){
   y <- as.numeric(as.factor(y))-1
   }
  
  if (length(x) != length(y))
    stop("x and y lengths differ")
  if (any(y < 0 | y > 1))
    stop("y not between 0 and 1")
  if (length(x) < 100 & is.null(binsize))
    stop("Less than 100 observations: specify binsize manually")
  
  if (is.null(binsize)) binsize = min(round(length(x)/10), 50)
  
  if (probit){
    link = qnorm
    if (is.null(main)) main = "Empirical probits"
  } else {
    link = function(x) log(x/(1-x))
    if (is.null(main)) main = "Empirical logits"
  }
  
  sort = order(x)
  x = x[sort]
  y = y[sort]
  a = seq(1, length(x), by=binsize)
  b = c(a[-1] - 1, length(x))
  
  prob = xmean = ns = rep(0, length(a)) # ns is for CIs
  for (i in 1:length(a)){
    range = (a[i]):(b[i])
    prob[i] = mean(y[range])
    xmean[i] = mean(x[range])
    ns[i] = b[i] - a[i] + 1 # for CI 
  }
  
  extreme = (prob == 1 | prob == 0)
  prob[prob == 0] = min(prob[!extreme])
  prob[prob == 1] = max(prob[!extreme])
  
  g = link(prob) # logits (or probits if probit == TRUE)
  
  linear.fit = lm(g[!extreme] ~ xmean[!extreme])
  b0 = linear.fit$coef[1]
  b1 = linear.fit$coef[2]
  
  loess.fit = loess(g[!extreme] ~ xmean[!extreme])
  
  plot(xmean, g, main=main, xlab=xlab, ylab=ylab)
  abline(b0,b1)
  if(lowess.in ==TRUE){
  lines(loess.fit$x, loess.fit$fitted, lwd=2, lty=2)
  }
}
```


```{r, fig.height=9, fig.width=9, fig.align='center', warning = FALSE}
# cluster of mosaic plots
op <- par( mfrow = c(2,3))

emplogitPlot(x=dengueClean[,2], y=dengueClean$Y, 
             xlab = "Age", 
             ylab = "Log Odds Dengue Fever", 
             main = "Age")

# emplogitPlot between Temperature and Dengue Fever
  emplogitPlot(x=dengueClean[,8], y=dengueClean$Y, 
             xlab = "Temperature (in Celsius)", 
             ylab = "Log Odds Dengue Fever", 
             main = "Temperature")


# empirical logit plot between BMI and Dengue Fever
  emplogitPlot(x=dengueClean[,9], y=dengueClean$Y, 
             xlab = "BMI", 
             ylab = "Dengue Fever", 
             main = "BMI")


# empirical logit plot between Height and Dengue Fever
  emplogitPlot(x=dengueClean[,10], y=dengueClean$Y, 
             xlab = "Height (in cm)", 
             ylab = "Dengue Fever", 
             main = "Height")


# empirical logit plot between Weight and Dengue Fever
  emplogitPlot(x=dengueClean[,11], y=dengueClean$Y, 
             xlab = "Weight (in kg)", 
             ylab = "Dengue Fever", 
             main = "Weight")
par(op)
```

\begin{center}
Figure 3.1.1: Relationship Analysis of Numerical Variables vs Log Odds Dengue Fever
\end{center}

  Figure 3.1.1 shows that age, temperature, BMI, and height have a strong linear relationship with the log odds of dengue fever, indicating that these four features should be added to the model with no need for transformation.

  However, the empirical logit plot between the log odds of dengue fever and the weight reflects a curved relationship, which is not linear, so it is necessary to perform the linear transformation to modify the relationship.

```{r, fig.align='center',fig.width=4.5, fig.height=3.5}
emplogitPlot(x=log(dengueClean$Weight), y=dengueClean$Y, 
             xlab = "Log Weight", 
             ylab = "Log Odds Dengue Fever", 
             main = " ")
```

\begin{center}
Figure 3.1.2: Log Weight vs Log Odds Dengue Fever
\end{center}

  Figure 3.1.2 indicates that, the log weight is strong linearly related with the log odds of dengue fever. Therefore, we add the log weight into our model.


### EDA (Part 3): Multicollinearity

  Besides checking the relationship between numerical features and the label, it is important to check if there is a linear relationship exists between features. Therefore, we use a correlation matrix to explore linear relationships between numerical features.

```{r}
senpai <- cor(dengueClean[,c(2,8,9,10,11)])
knitr::kable(senpai, caption = "Correlation Matrix of Numerical Variables")
```

From the table, Height and Weight are strongly related to Age with a correlation larger than 0.8. The reason behind this is that the patient's age was no greater than 15 years old, so children's age is a direct indicator of their physique as they grow fast. Therefore, we could keep age as the only indicator in the model and remove the height and weight, which are redundant.



### EDA (Part 4): Categorical variables analysis

  Along with the numerical variables, we use mosaic plot to select categorical features with statistically significant influences of the outcome.

```{r, fig.width=9, fig.height=9}
op <- par(mfrow=c(3,3))

# dengue fever here is not log odds
mosaicplot(dengueClean$Sex  ~ dengueClean$Y, col = c("yellow", "cyan"),xlab = "Sex", ylab = "Dengue Fever", main = "Sex vs Dengue Fever")
mosaicplot(dengueClean$DayDisease  ~ dengueClean$Y, col = c("red", "green"),xlab = "Days of Disease", ylab = "Dengue Fever", main = "Days of Disease vs Dengue Fever")
mosaicplot(dengueClean$Vomiting  ~ dengueClean$Y, col = c("yellow", "cyan"),xlab = "Vomitting", ylab = "Dengue Fever", main = "Vomitting vs Dengue Fever")
mosaicplot(dengueClean$Abdo  ~ dengueClean$Y, col = c("red", "green"),xlab = "Abdominal Pain", ylab = "Dengue Fever", main = "Abdominal Pain vs Dengue Fever")

mosaicplot(dengueClean$Muco  ~ dengueClean$Y, col = c("yellow", "red"),xlab = "Mucosal Bleeding", ylab = "Dengue Fever", main = "Mucosal Bleeding vs Dengue Fever")
mosaicplot(dengueClean$Skin  ~ dengueClean$Y, col = c("brown", "green"),xlab = "Skin", ylab = "Dengue Fever", main = "Skin vs Dengue Fever")
# we need to convert True/False categories into numerical expressions (0/1)
mosaicplot(as.numeric(dengueClean$Flush)  ~ dengueClean$Y, col = c("orange", "cyan"),xlab = "Flush", ylab = "Dengue Fever", main = "Flush vs Dengue Fever")
mosaicplot(as.numeric(dengueClean$Hepatomegaly)  ~ dengueClean$Y, col = c("blue", "green"),xlab = "Hepatomegaly", ylab = "Dengue Fever", main = "Hepatomegaly vs Dengue Fever")
mosaicplot(as.numeric(dengueClean$Rash)  ~ dengueClean$Y, col = c("cyan", "gray"),xlab = "Rash", ylab = "Dengue Fever", main = "Rash vs Dengue Fever")
par(op)
```

\begin{center}
Figure 3.1.3: Relationship Analysis of Categorical Variables and Dengue Fever
\end{center}

  From Figure 3.1.3, we see that there is no relationship between sex and dengue fever. Although there is an evident change in the proportion of outcomes with different categories for hepatomegaly, one category dominates the entire feature and is therefore unlikely to have statistically significant influence on the outcome. Therefore, both sex and hepatomegaly are excluded from the model.


## 3.2: Model building and training 

  In section 3.2, we will construct model with the variables selected from the EDA: DayDisease, Vomiting, Abdo, Muco, Skin, Flush, Rash, Age, Temp, and BMI. We applied the train-test split method in this case to explore the prediction capacity of the model.


### Model 1 Construction & Coefficients Evaluation

```{r}
# Model Building: m1

# make the model and print the coefficient at the end
m1 <- glm(as.factor(Y) ~ DayDisease + Vomiting + Abdo + Muco + Skin + Flush + Rash + Age + Temp + BMI, data = dengueClean, family = "binomial")

# summarize the information of the model
knitr::kable(round(summary(m1)$coefficients,3), caption = "Coefficients Table of Logistic Model 1")  
```

  From the critical test, we could see that the P-values for Abdo, Muco, and RashTRUE are all over 0.05. This means that given all features are added to the model, based on 95% of confidence, we failed to testify that there is a statistically significant relationship existed between these features and the response variable. Therefore, I recommend removing these variables from the model. If the remaining variable still performs relatively same level of prediction capacity, then we should adopt the simpler model.

### Model 2 Construction & Coefficients Evaluation

```{r}
# Model Building: m2
# Check the deviance
m2 <- glm(as.factor(Y) ~ DayDisease + Vomiting + Skin + Flush + Age + Temp + BMI, data = dengueClean, family = "binomial")
knitr::kable(round(summary(m2)$coefficients,3), caption = "Coefficients Table of Logistic Model 2")  
```
  From the table, all features in model 2 has p-value less than 0.05, indicating that there is a statistical significant relationship between each feature and the label dengue fever.


\pagebreak


### AIC Table of Model 1 & Model 2

```{r}
# AIC table between the m1 and m2
aic <-c(AIC(m1),AIC(m2))
aic <- matrix(aic, nrow = 2, ncol = 1)   # create the matrix
rownames(aic) <- c("Model 1", "Model 2")  # rename the columns

# table
knitr::kable(aic, col = "AIC values", caption = "AIC Table of M1 & M2")
```

  From the table, the Model 2 has smaller AIC than the model 1. This indicates that, after removing all these variables, the performance of the model 2 better fits the data. Therefore, we should select model 2 as the candidate.



## 3.3: Prediction & Result Evaluation

  In KNN section, our result proves that the data size is large enough that the influence from the selection of observations does not influence the prediction capacity of the model. Therefore, we also apply the train-test split method in logistic model and make predictions with threshold of 0.5.

```{r}
# we will put the same train-test data as previous so that it is easier to compare the outcomes and thus the relationship between two variables
set.seed(114514)
# train-test split
# randomly sample the numbers from an ordered vector from 1 to 5726 to represent the 
# row indices for the testing set, later we could directly slice the data with the 
# indices collected here
testRow <- sample(1:nrow(dengueClean), nrow(dengueClean)*0.2)   

# creating the test set with observations with indices in testRow vector (20% of total data)
newTest <- dengueClean[testRow,]  

# creating the training set with observations with indices not in testRow vector (80% of total data)
newTrain <- dengueClean[-testRow,]

# find the number of positive dengue cases in newTest
trueDengueS <- which(newTest$Y == 1)
ntrueDengueS <- length(trueDengueS)

# find the number of negative dengue cases in newTest
trueNotDengueS <- which(newTest$Y == 0)
ntrueNotDengueS <- length(trueNotDengueS)
```


```{r}
# predict the Y of the testing set with threshold 0.5

# If p >= 0.5, it should be dengue fever, if p <= 0.5, not dengue fever
probabilities <- predict(m2, newdata = newTest, type = "resp")
predicted.Y <- ifelse(probabilities >= 0.5, "1", "0") # classify the result
    
# print(length(which(predicted.Y == 0)))
# print(length(which(predicted.Y == 1)))
```

  Model 2 predicts 209 patients who are not dengue and 936 person who is dengue. The total prediction numbers equal the observations in the test dataset. To determine the accuracy of the prediction, we construct the confusion matrix for analysis.

### Confusion Matrix of Logistic Regression Model (Model 2)

```{r}
# confusion matrix
knitr::kable(table(predicted.Y, newTest$Y), caption= "Confusion Matrix of Logistic Regression", col = c("True Not Dengue", "True Dengue"))
```


### Metrics Computation

$$
Sensitivity = \frac{True Dengue \ \& \ Predicted True Dengue}{Total \ True Dengue} = \frac{717}{717 + 86} \approx 0.892
$$

$$
Specificity = \frac{True Not Dengue\ \& \ Predicted\  True Not Dengue}{Total \ True Not Dengue} = \frac{123}{123 + 219} \approx 0.360
$$

$$
Accuracy = \frac{Total \ Correct \ Predictions}{Total \ Observations} = \frac{717 + 123}{717 + 123 + 86 + 219} \approx 0.734
$$



\pagebreak

# Section 4: Compare and Evaluate: Logistic/KNN

### Summary Table

\begin{center}
\textbf{Summary Table of Metrics (Logistic vs KNN)}
\end{center}

|                                                   |
|------------|-------------|-------------|----------|
|            | Sensitivity | Specificity | Accuracy |
|------------|-------------|-------------|----------|
|     KNN    | 86.5%       | 35.3%       | 71.3%    |
|  Logistic  | 89.2%       | 36.0%       | 73.4%    |


### Conclusion
  From the summary table, the logistic regression model outperformed the  KNN-based model in all three metrics in the summary table. Therefore, we could conclude that the multivariable logistic regression model is more effective in predicting dengue fever through the symptoms, and Model 2 should be adapted as our final choice.

  The logistic regression model is also more effective for the prediction of higher-dimension data compared with KNN. Without the help of the computer, client could compute the log odds of the dengue by hand and make predictions based on the threshold, while the KNN-based model examines the clusters in high dimension, which is difficult for visualization or computation. In underdeveloped areas, logistic regression is a better choice because advanced computational tools are unlikely to be available. Therefore, for practical consideration, logistic regression is also a better choice for clients.


