---
title: "STA363_Lab_7"
author: "Zishan Shao"
date: "2022-11-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


```{r, warning =FALSE}
# import the data
suppressMessages(library(palmerpenguins))
data(penguins)
penguins <- na.omit(penguins)
```


# Question 1:

*Is this an association task or a prediction task?*

**ANS: ** The client is very interested in understanding the relationship between different values of features & higher body mass, so it is an association task.



# Question 2:

*In the root, what is the predicted value Y_hat i for all penguins?*

**ANS: ** It should be the mean value of the given response variable. In this case, it should be roughly 4207.1 g.

```{r}
Y <- penguins$body_mass_g
Ym <- sum(penguins$body_mass_g)/length(penguins$body_mass_g)
```


# Question 3:

*What is the RSS and RMSE with all the data in the root node (i.e, using no features)?*

**ANS: ** In this case, the RSS should be 215259666, and the RMSE is about 804.0

```{r}
# RSS
Y_Resid_Squared <- sum((Y - Ym)^2)
Y_Resid_Squared

# RMSE
sqrt(Y_Resid_Squared / length(Y))

# knowing the information about the root gives us an idea of the starting point of our tree
```



# Question 4:

*With species as a feature, what are all the possible splitting rules we could use to divide the root into two leaves? Note: Order doesn’t matter.*

**ANS: ** There are three categories for the species. Therefore, we will have 3 possible splitting rules: Gentoo - not Gentoo (Adelie or Chinstrap), Adelie - not Adelie (Chinstrap or Gentoo), Chinstrap - not Chinstrap (Gentoo or Adelie)


# Question 5:

*Find the training RSS that we would get if we built a tree with one split using each of the splitting rules from Question 4. Show your code and the RSS for each splitting rule. Hint: A for loop helps here but is not required. Write out the steps in words before you start to code. This will help you figure out what each line of code needs to do.*

**ANS: ** 

```{r, echo=TRUE}
# we use the for loop to seek the training RSS of all three splitting rules

storage <- data.frame("Rule" = rep(NA, 3), "RSS" = rep(NA, 3))
preds <- rep(0, nrow(penguins))

cats <- unique(penguins$species)

for (i in 1:length(cats)) {
  # the splitting rule i: where splitting rule is cats[i] on left and cats[-i] on right of the tree
  rule <- which(penguins$species == cats[i])
  
  # treeLeft is the value that is cats[i]
  treeleft <- penguins[rule,]
  # treeRight is the value that is cats[-i]
  treeright <- penguins[-rule,]
  
  # Make predictions
  preds[rule] <- sum(treeleft$body_mass_g)/length(treeleft$body_mass_g)
  preds[-rule] <- sum(treeright$body_mass_g)/length(treeright$body_mass_g)
  
  # calculate the RSS of the tree
  RSS <- sum((penguins$body_mass_g - preds) ^ 2)
  
  # store the information of the RSS & splitting rule
  storage$Rule[i] <- paste0("Rule " , as.character(i), ": ", cats[i])
  storage$RSS[i] <- RSS
}

knitr::kable(storage)
```


# Question 6:

*Based on this, which splitting rule would you recommend we use to split the root node into two leaves? What is the percent reduction in RSS you get with this split (comparing to the root RSS)?*

**ANS: ** The Rule 2 gives the least RSS, so we should use Rule 2, which is Gentoo and not Gentoo [Adelie or Chinstrap]. The untrained model will have RSS = 215259666, so we will have a (70103076 - 215259666) / 215259666 = 67.4% of reduction in RSS.

```{r}
# (70103076 - 215259666) / 215259666
```



```{r, warning=FALSE}
# Grows the tree
suppressMessages(library(rpart))
# Allows us to visualize the tree
suppressMessages(library(rattle))
suppressMessages(library(rpart.plot))

# build a tree with one feature (species) and only one split
tree1<- rpart(body_mass_g ~ species, data = penguins, method = "anova", maxdepth = 1)
# anova to tell R that we are fitting a regression tree
# The maxdepth=1 --> only allowing one split in the tree; if not specified, continue until hits the built-in stopping rules

op <- par( mfrow = c(1,2))
# Advantage: highly interpretable
# Option 1 
fancyRpartPlot(tree1, sub = " ")

# Option 2 
prp(tree1, sub = " ")

par(op)

title("Figure 1: One Split based on Species")

# The sub= part of the code is where you add a title to your tree. It is much easier in a tree to add a title at the bottom rather than at the top - there is more space.
```



# Question 7:

*What percent of penguins are in leaf 2?*

**ANS: ** There are 119 penguins in leaf 2, where there are totally 333 penguins, so the percentage of penguins in leaf 2 is (333-119) / 333 * 100% = 35.7%

```{r}
# 214 / 333
cc <- c(rep(NA, 10))
cc[c(1,2,4)] <- 2
cc
```



# Question 8:

*What body mass does the tree predict for all Chinstrap penguins?*

**ANS: ** Based on the information in leaf 2, the body mass for all Chinstrap penguins is expected to be 3715 grams.



# Question 9:

*Fit a least squares linear regression model for body mass, using whether or not a penguin is a Gentoo penguin as a feature. Call this model LSLR1. Write out the fitted regression line. Hint: To specify an indicator variable for a specific level of a categorical variable, you can use, for instance, (species==“Adelie”). The ( ) are important.*

**ANS: ** 

```{r}
LSLR1 <- lm(body_mass_g ~ (species == "Gentoo"), data = penguins)
summary(LSLR1)


# When we start adding in multiple features, or when the features are numeric, we will find that trees and LSLR models are not the same.
```

The fitted regression line was:

$$LSLR1: \hat{BodyMass} = 3714.72 + 1377.72 \ Species(Gentoo)$$

# Question 10:

*Based on the regression model, what body mass would you predict for a Chinstrap penguin? Keeping in mind that in the visualization our trees round to the nearest whole number, how do these predictions compare to those you made from the tree?*

**ANS: ** For a chinstrap penguin, the category Gentoo is false, so the predicted value of the body mass should be equals to the intercept, that is 3714.72, about 3715 grams, which is exactly the same as the predictions made by the regression tree.



# Question 11:

*Find the training RSS that we would get if we built a tree with one split using each of the possible splitting rules on flipper length. Show your code and the RSS for each splitting rule. Which splitting rule should we use? Hint: A for loop helps is required here. Write out the steps in words before you start to code. This will help you figure out what each line of code needs to do.*

**ANS: ** 


```{r, echo=TRUE}
# we use the for loop to seek the training RSS of all splitting rules for the flipper_length

cats <- unique(penguins$flipper_length_mm)

storage <- data.frame("Rule" = rep(NA, length(cats)), "RSS" = rep(NA, length(cats)))
preds <- rep(0, nrow(penguins))

for (i in 1:length(cats)) {
  # the splitting rule i: where splitting rule is cats[i] on left and cats[-i] on right of the tree
  rule <- which(penguins$flipper_length_mm < cats[i]) # if <=, then number 48 = 0
  
  # treeLeft is the value that is cats[i]
  treeleft <- penguins[rule,]
  # treeRight is the value that is cats[-i]
  treeright <- penguins[-rule,]
  
  # Make predictions
  preds[rule] <- sum(treeleft$body_mass_g)/length(treeleft$body_mass_g)
  preds[-rule] <- sum(treeright$body_mass_g)/length(treeright$body_mass_g)
  
  # calculate the RSS of the tree
  RSS <- sum((penguins$body_mass_g - preds) ^ 2)
  
  # store the information of the RSS & splitting rule
  storage$Rule[i] <- paste0("Rule " , as.character(i), ": ", cats[i])
  storage$RSS[i] <- RSS
}

knitr::kable(storage)

cats[which.min(storage$RSS)]
```

Based on the outputs, we should use the splitting rule 45, which is the case that the flipper length less than mm or not. This returns the RSS = 74208480.


# Question 12:

*Create a tree using only flipper length as a feature (this means you should not include species in this tree). Use the maxdepth = 1 stopping criterion to make sure that for the moment, the tree only has one split. Call the tree tree2, and show a visualization of your tree as your answer to this question (Figure 2).*

**ANS: ** 


```{r}
#  create the tree based on the flipper length
tree2<- rpart(body_mass_g ~ flipper_length_mm, data = penguins, method = "anova", maxdepth = 1)
fancyRpartPlot(tree2, sub = "Figure 2: One Split on Flipper Length (in mm)")
```



# Question 13:

*Based on your tree, what body mass would you predict for a penguin with a flipper length of 210 mm?*

**ANS: ** The body mass of a penguin with flipper length of 210 mm is in category of flipper length larger than 207 mm. Thus, we expect its weight to be 5047 grams.



# Question 14:

*Fit a least squares linear regression model for body mass, using flipper length as the only feature. Call this model LSLR2 and write out the fitted regression line.*

**ANS: ** 

```{r}
LSLR2 <- lm(body_mass_g ~ flipper_length_mm, data = penguins)
summary(LSLR2)
```

The fitted regression line in this case is: 
$$LSLR2: \hat{BodyMass} = -5872.09 + 50.15 \ FlipperLength$$


# Question 15:

*Based on your LSLR line, what body mass would you predict for a penguin with a flipper length of 210 mm? How does this compare to what you get from a tree?*

**ANS: ** The LSLR model predicts that the body mass of a penguin with flipper length of 210 mm is 4659.41. This value is smaller than the value predicted by the regression tree, which is 5047 grams.

```{r}
# -5872.09 + 50.15*210
```


# Question 16:

*Find the RMSE for your tree and for your LSLR model with flipper length as a feature. Based on training metrics, which model is a stronger fit to the sample data?*

**ANS: ** The RMSE of the LSLR model (LSLR2) is smaller than the RMSE of the regression tree model (tree2). Therefore, the LSLR model is a stronger fit to the sample data.

```{r}
# RMSE of the tree2
RMSEtree <- sqrt(min(storage$RSS)/nrow(penguins))  

# RMSE of LSLR2
RMSElslr <- 393.3 # the residual standard error

RMSEs <- data.frame("Model" = c("Tree", "LSLR"), "RMSE" = c(RMSEtree, RMSElslr))
knitr::kable(RMSEs)
```



# Question 17:

*Build a tree using flipper length as a feature, but this time allow 3 splits. Plot your tree and label your image Figure 3.*

**ANS: ** 

```{r}
#  create the tree based on the flipper length with 3 splits
tree3<- rpart(body_mass_g ~ flipper_length_mm, data = penguins, method = "anova", maxdepth = 2)
fancyRpartPlot(tree3, sub = "Figure 3: Three Splits on Flipper Length (in mm)")
```


# Question 18:

*Create a tree using all possible features in the data. Do not restrict the number of splits. Call the tree tree4, and show a visualization of your tree as your answer.*

**ANS: ** 

```{r}
#  create the tree 4 based on all features in penguins
tree4<- rpart(body_mass_g ~ ., data = penguins, method = "anova")
fancyRpartPlot(tree4, sub = "Figure 4: Regression Tree of All Features")
```



# Question 19:

*Which features does your tree use?*

**ANS: ** The tree uses the feature sex and species in the model.



# Question 20:

*In Tree 4, which feature was able to give us the largest reduction in training RSS in one split?*

**ANS: ** 

```{r}
# the RSS after introducing sex
a <- sum( (penguins$body_mass_g - predict(tree4))^2 )

# the RSS before introducing sex
b <- sum( (penguins$body_mass_g - predict(tree1))^2 )

# percent RSS loss for sex
pct_a <- (b - a) / b

# original RSS
c <- 215259666

# percent RSS loss for species
pct_b <- (c - b) / c

# pct_a
# pct_b
```

The tree uses the species as the first splitting rule, so species is the feature that lead to most reduction in RSS.
This was also indicated by the RSS. Introducing the sex lead to 54.2% of reduction in RSS, while introducing the species lead to 67.4% of reduction in RSS. Therefore, introducing the species give us the largest reduction in one split.



# Question 21:

*Based on Tree 4, what is the predicted body mass for the 3rd penguin in the data set?*

**ANS: ** 

```{r}
# get the information of predicted third penguin
predict(tree4)[3]
```

The predicted body mass of 3rd penguin, which is a female Adelie penguin, should be 3419.2 grams.


# Question 22:

*Type the code ?rpart.control into a chunk, and hit play, and then put a # in front of the code. What will pop up is the R help page. This page shows all of the stopping criteria you can choose to use when growing a tree. It also shows (in the code at the top) the default stopping criteria that R uses if we don’t specify our own. What is the default number of rows that have to be in a leaf in order for it to split?*

**ANS: ** 

```{r}
# ?rpart.control
```

The default number of observations that must exist in a node for a split is 20 (indicated by the minsplit).


# Question 23:

*Create a tree using all the features, but this time add the stopping rule that the R-squared needs to increase by .1% (.001) in order to split. Call this tree 5. Show your result and discuss the changes in the tree.*

**ANS: ** 

```{r}
#  create the tree 4 based on all features in penguins
tree5<- rpart(body_mass_g ~ ., data = penguins, method = "anova", cp = 0.001) # so that the R-squared needs to increase by 0.001 at each steo
# fancyRpartPlot(tree5, sub = "Figure 5: Regression Tree with Stopping Rule")

prp(tree5,sub = "Figure 5: Regression Tree with Stopping Rule")

aa <- c(1,1,1,1,2,2,2,2)
preds <- mean(aa)
Yi_hat <- rep(0, length(aa))
Yi_hat
for(i in 1:length(aa)) {
  Yi_hat[i] <- preds
}
Yi_hat

sum((aa - Yi_hat)^2)

# this tree takes 6 steps because the furthest branches has 6 splitting rules
```

Now the tree has more depth (depth = 6) than the tree4 (indicated by Figure 4). The increasing number of splitting rules added to the tree result in an increase in complexity of the tree. Now the tree has 221 leaves.


# Question 24:

*The client wanted to know what penguin traits were associated with higher body mass. Based on your tree, respond to the client’s question.*

**ANS: ** Based on the tree, the male Gentoo penguin is expected to have higher body mass.
